{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcGQpUmO8U/fYfgjr7+U/y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xjdeng/mbtimodel/blob/main/reddit_gemini_query.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDj3PupYtoS_"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/xjdeng/mbtimodel\n",
        "!pip install praw google-generativeai path.py==12.0.1\n",
        "!pip install -r mbtimodel/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import praw\n",
        "from google.colab import userdata\n",
        "import bs4\n",
        "import markdown\n",
        "import re\n",
        "import pandas as pd\n",
        "import praw\n",
        "from prawcore.exceptions import NotFound\n",
        "import string\n",
        "import google.generativeai as genai\n",
        "import enum\n",
        "from typing_extensions import TypedDict\n",
        "import pprint\n",
        "from path import Path as path\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "SVCCuRL5t2To"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# IMPORTANT: Set up your Reddit AND your Gemini credentials and enter them into your Google Colab Secrets\n",
        "# See Vid for instructions, for Reddit: https://www.youtube.com/watch?v=VAJFZEeKjSY\n",
        "# For Gemini: https://www.youtube.com/watch?v=S1elvCs1gyI\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "assert GOOGLE_API_KEY is not None\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "client_id = userdata.get(\"reddit_client_id\")\n",
        "assert client_id is not None\n",
        "client_secret = userdata.get(\"reddit_client_secret\")\n",
        "assert client_secret is not None\n",
        "username = userdata.get(\"reddit_username\")\n",
        "assert username is not None\n",
        "password = userdata.get(\"reddit_password\")\n",
        "assert password is not None\n",
        "app_name = userdata.get(\"reddit_app\")\n",
        "reddit = praw.Reddit(client_id=client_id,\n",
        "                     client_secret=client_secret,\n",
        "                     user_agent=app_name,\n",
        "                     username=username, \\\n",
        "                     password=password)\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash-latest\")"
      ],
      "metadata": {
        "id": "sVuG23wMt9P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Confidence(enum.Enum):\n",
        "  low = \"low\"\n",
        "  medium = \"medium\"\n",
        "  high = \"high\"\n",
        "\n",
        "class answer(TypedDict):\n",
        "    answer: str\n",
        "    confidence: Confidence\n",
        "    explanation: str\n",
        "\n",
        "def noquotes(text):\n",
        "    \"\"\"\n",
        "This function first stated out as a way to remove markdown quotes from raw reddit markdown text but now it's more of a\n",
        "general purpose text parser, but the name hasn't changed.\n",
        "    \"\"\"\n",
        "    #https://stackoverflow.com/questions/761824/python-how-to-convert-markdown-formatted-text-to-text\n",
        "    html = markdown.markdown(text)\n",
        "    text = ''.join(bs4.BeautifulSoup(html, 'lxml').findAll(string=True))\n",
        "    t1 = re.sub(\">.+?(\\n|$)\",\"\",text).replace(\"\\\\n\",\"\").replace(\"\\\\\",\"\")\n",
        "    return t1\n",
        "\n",
        "def query_history(query, history):\n",
        "    prompt = f\"\"\"\n",
        "    I want make the following query about a particular reddit user based on their comments and submissions in this Reddit history.\n",
        "    Please pay close attention to the dates of the comments and submissions and pay more attention to the more recent dates.\n",
        "    If something the user says conflicts with an earlier comment or submission they made, assume they've changed and the more recent one is more likely true now.\n",
        "\n",
        "    Query:\n",
        "    ---\n",
        "    {query}\n",
        "    ---\n",
        "\n",
        "    Please answer to this query, state an explanation for why you chose your answer, and state your confidence level in your answer.\n",
        "\n",
        "    Reddit History:\n",
        "    ---\n",
        "    {history}\n",
        "    ---\n",
        "\n",
        "    \"\"\"\n",
        "    result = model.generate_content(prompt,\n",
        "                                    generation_config = genai.GenerationConfig(\n",
        "                                        response_mime_type=\"application/json\", response_schema=answer\n",
        "                                    ))\n",
        "    return result\n",
        "\n",
        "path(\"tmp\").mkdir_p()\n",
        "\n",
        "def query_user(username, query):\n",
        "    try:\n",
        "        userfile = f\"tmp/{username}.txt\"\n",
        "        if path(userfile).exists():\n",
        "            with open(userfile) as f:\n",
        "                fulltext = f.read()\n",
        "        else:\n",
        "            comms = list(reddit.redditor(username).comments.new(limit=None))\n",
        "            subs = list(reddit.redditor(username).submissions.new(limit=None))\n",
        "            text = []\n",
        "            for comment in comms:\n",
        "                comment_date = datetime.utcfromtimestamp(comment.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n",
        "                text.append(f\"[Comment Date: {comment_date}]\\n{noquotes(comment.body)}\")\n",
        "            for sub in subs:\n",
        "                sub_date = datetime.utcfromtimestamp(sub.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n",
        "                newsub = noquotes(sub.selftext)\n",
        "                if len(newsub) > 0:\n",
        "                    text.append(f\"[Submission Date: {sub_date}]\\n{newsub}\")\n",
        "            fulltext = \"\\n\\n\\n\".join(text)\n",
        "            with open(userfile, 'w') as f:\n",
        "                f.write(fulltext)\n",
        "        return query_history(query, fulltext).to_dict()['candidates'][0]['content']['parts'][0]['text']\n",
        "    except NotFound:\n",
        "        return None"
      ],
      "metadata": {
        "id": "-6PyO6B8t_Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = query_user(\"thisisbillgates\", \"Does this user like bacon?\")\n",
        "pprint.pprint(result)"
      ],
      "metadata": {
        "id": "wQPw8F46AGAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WzemMhbMU3aC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}