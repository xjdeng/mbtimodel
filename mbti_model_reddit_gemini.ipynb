{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBZO4nV1k4hDKQY+Hn177T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xjdeng/mbtimodel/blob/main/mbti_model_reddit_gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDj3PupYtoS_"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/xjdeng/mbtimodel\n",
        "!pip install praw google-generativeai\n",
        "!pip install -r mbtimodel/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import praw\n",
        "from google.colab import userdata\n",
        "import bs4\n",
        "import markdown\n",
        "import re\n",
        "import pandas as pd\n",
        "import praw\n",
        "from prawcore.exceptions import NotFound\n",
        "import string\n",
        "import google.generativeai as genai\n",
        "import enum\n",
        "from typing_extensions import TypedDict\n",
        "import pprint"
      ],
      "metadata": {
        "id": "SVCCuRL5t2To"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# IMPORTANT: Set up your Reddit AND your Gemini credentials and enter them into your Google Colab Secrets\n",
        "# See Vid for instructions, for Reddit: https://www.youtube.com/watch?v=VAJFZEeKjSY\n",
        "# For Gemini: https://www.youtube.com/watch?v=S1elvCs1gyI\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "assert GOOGLE_API_KEY is not None\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "client_id = userdata.get(\"reddit_client_id\")\n",
        "assert client_id is not None\n",
        "client_secret = userdata.get(\"reddit_client_secret\")\n",
        "assert client_secret is not None\n",
        "username = userdata.get(\"reddit_username\")\n",
        "assert username is not None\n",
        "password = userdata.get(\"reddit_password\")\n",
        "assert password is not None\n",
        "app_name = userdata.get(\"reddit_app\")\n",
        "reddit = praw.Reddit(client_id=client_id,\n",
        "                     client_secret=client_secret,\n",
        "                     user_agent=app_name,\n",
        "                     username=username, \\\n",
        "                     password=password)\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash-latest\")"
      ],
      "metadata": {
        "id": "sVuG23wMt9P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MBTI(enum.Enum):\n",
        "    ISTJ = \"ISTJ\"\n",
        "    ISFJ = \"ISFJ\"\n",
        "    INFJ = \"INFJ\"\n",
        "    INTJ = \"INTJ\"\n",
        "    ISTP = \"ISTP\"\n",
        "    ISFP = \"ISFP\"\n",
        "    INFP = \"INFP\"\n",
        "    INTP = \"INTP\"\n",
        "    ENTP = \"ENTP\"\n",
        "    ESTP = \"ESTP\"\n",
        "    ESFP = \"ESFP\"\n",
        "    ENFP = \"ENFP\"\n",
        "    ESTJ = \"ESTJ\"\n",
        "    ESFJ = \"ESFJ\"\n",
        "    ENFJ = \"ENFJ\"\n",
        "    ENTJ = \"ENTJ\"\n",
        "\n",
        "class Confidence(enum.Enum):\n",
        "  low = \"low\"\n",
        "  medium = \"medium\"\n",
        "  high = \"high\"\n",
        "\n",
        "class Personality(TypedDict):\n",
        "    personality: MBTI\n",
        "    confidence: Confidence\n",
        "    explanation: str\n",
        "\n",
        "def noquotes(text):\n",
        "    \"\"\"\n",
        "This function first stated out as a way to remove markdown quotes from raw reddit markdown text but now it's more of a\n",
        "general purpose text parser, but the name hasn't changed.\n",
        "    \"\"\"\n",
        "    #https://stackoverflow.com/questions/761824/python-how-to-convert-markdown-formatted-text-to-text\n",
        "    html = markdown.markdown(text)\n",
        "    text = ''.join(bs4.BeautifulSoup(html, 'lxml').findAll(string=True))\n",
        "    t1 = re.sub(\">.+?(\\n|$)\",\"\",text).replace(\"\\\\n\",\"\").replace(\"\\\\\",\"\")\n",
        "    return t1\n",
        "\n",
        "\n",
        "\n",
        "def predict_mbti_txt(txt):\n",
        "    prompt = f\"\"\"\n",
        "    The follow is a list of comments and posts by a particular Reddit user. Predict their MBTI (Myer-Briggs) type to the best of your ability. When making the prediction, disregard any type the user claims to be and make the judgement yourself.\n",
        "    Please also state your confidence in the prediction and give an explanation for the type you chose and your confidence in it. You may also discuss other potential types in the explanation.\n",
        "\n",
        "    Comments:\n",
        "    ---\n",
        "    {txt}\n",
        "    ---\n",
        "    \"\"\"\n",
        "    result = model.generate_content(prompt,\n",
        "                                    generation_config = genai.GenerationConfig(\n",
        "                                        response_mime_type=\"application/json\", response_schema=Personality\n",
        "                                    ))\n",
        "    return result\n",
        "\n",
        "def predict_user(username):\n",
        "    try:\n",
        "        comms = list(reddit.redditor(username).comments.new(limit=None))\n",
        "        subs = list(reddit.redditor(username).submissions.new(limit=None))\n",
        "        text = []\n",
        "        ups = 0\n",
        "        downs = 0\n",
        "        for comment in comms:\n",
        "            text.append(noquotes(comment.body))\n",
        "            votes = comment.ups - 1\n",
        "            if comment.controversiality == 1:\n",
        "                extent = abs(votes)*1.5 + 3\n",
        "                ups += int(round(votes + extent))\n",
        "                downs += int(round(votes - extent))\n",
        "            else:\n",
        "                if votes > 0:\n",
        "                    ups += votes\n",
        "                else:\n",
        "                    downs += votes\n",
        "        for sub in subs:\n",
        "            newsub = noquotes(sub.selftext)\n",
        "            if len(newsub) > 0:\n",
        "                text.append(newsub)\n",
        "        fulltext = \"\\n\\n\\n\".join(text)\n",
        "        A = abs(ups)\n",
        "        B = abs(downs)\n",
        "        controversiality = B/(A+B)\n",
        "        return predict_mbti_txt(fulltext).to_dict()['candidates'][0]['content']['parts'][0]['text'], controversiality\n",
        "    except NotFound:\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "-6PyO6B8t_Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = predict_user(\"lexfridman\")\n",
        "pprint.pprint(result)"
      ],
      "metadata": {
        "id": "wQPw8F46AGAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WzemMhbMU3aC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}